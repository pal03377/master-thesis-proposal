
@article{mlFeedbackOnTextualStudentAnswersInLargeCourses,
  abstract   = {Many engineering disciplines require problem-solving skills, which cannot be learned by memorization alone. Open-ended textual exercises allow students to acquire these skills. Students can learn from their mistakes when instructors provide individual feedback. However, grading these exercises is often a manual, repetitive, and time-consuming activity. The number of computer science students graduating per year has steadily increased over the last decade. This rise has led to large courses that cause a heavy workload for instructors, especially if they provide individual feedback to students. This article presents CoFee, a framework to generate and suggest computer-aided feedback for textual exercises based on machine learning. CoFee utilizes a segment-based grading concept, which links feedback to text segments. CoFee automates grading based on topic modeling and an assessment knowledge repository acquired during previous assessments. A language model builds an intermediate representation of the text segments. Hierarchical clustering identifies groups of similar text segments to reduce the grading overhead. We first demonstrated the CoFee framework in a small laboratory experiment in 2019, which showed that the grading overhead could be reduced by 85%. This experiment confirmed the feasibility of automating the grading process for problem-solving exercises. We then evaluated CoFee in a large course at the Technical University of Munich from 2019 to 2021, with up to 2, 200 enrolled students per course. We collected data from 34 exercises offered in each of these courses. On average, CoFee suggested feedback for 45% of the submissions. 92% (Positive Predictive Value) of these suggestions were precise and, therefore, accepted by the instructors.},
  author     = {Jan Philip Bernius and Stephan Krusche and Bernd Bruegge},
  doi        = {https://doi.org/10.1016/j.caeai.2022.100081},
  issn       = {2666-920X},
  journal    = {Computers and Education: Artificial Intelligence},
  keywords   = {Software engineering, Education, Interactive learning, Automatic assessment, Grading, Assessment support system, Learning, Feedback},
  pages      = {100081},
  title      = {Machine learning based feedback on textual student answers in large courses},
  url        = {https://www.sciencedirect.com/science/article/pii/S2666920X22000364},
  volume     = {3},
  year       = {2022},
  bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S2666920X22000364},
  bdsk-url-2 = {https://doi.org/10.1016/j.caeai.2022.100081}
}

@misc{deepContextualizedWordRepresentations,
  doi       = {10.48550/ARXIV.1802.05365},
  url       = {https://arxiv.org/abs/1802.05365},
  author    = {Peters, Matthew E. and Neumann, Mark and Iyyer, Mohit and Gardner, Matt and Clark, Christopher and Lee, Kenton and Zettlemoyer, Luke},
  keywords  = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Deep contextualized word representations},
  publisher = {arXiv},
  year      = {2018},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{hdbsc,
  author    = {McInnes, Leland and Healy, John},
  booktitle = {2017 IEEE International Conference on Data Mining Workshops (ICDMW)},
  title     = {Accelerated Hierarchical Density Based Clustering},
  year      = {2017},
  volume    = {},
  number    = {},
  pages     = {33-42},
  doi       = {10.1109/ICDMW.2017.12}
}